{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors: 1\n",
      "Vector dimension: 768\n",
      "Vector names: ['my_custom_vector']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sae_dashboard.neuronpedia.vector_set import VectorSet\n",
    "# First, create a sample JSON file with a single vector\n",
    "\n",
    "# initialize a random vector\n",
    "vector = torch.randn(768)\n",
    "\n",
    "vector_data = {\n",
    "    \"vectors\": [\n",
    "        vector.tolist()\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "json_path = Path(\"sample_vector.json\")\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(vector_data, f)\n",
    "\n",
    "# Load the vector into a VectorSet\n",
    "vector_set = VectorSet.from_json(\n",
    "    json_path=json_path,\n",
    "    d_model=768,  # Example dimension for GPT-2 Small\n",
    "    hook_point=\"blocks.0.hook_resid_pre\",\n",
    "    hook_layer=0,\n",
    "    model_name=\"gpt2\",\n",
    "    names=[\"my_custom_vector\"]  # Optional custom name\n",
    ")\n",
    "\n",
    "# Now you can use the vector set\n",
    "print(f\"Number of vectors: {vector_set.vectors.shape[0]}\")\n",
    "print(f\"Vector dimension: {vector_set.vectors.shape[1]}\")\n",
    "print(f\"Vector names: {vector_set.names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_set.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sae_dashboard.neuronpedia.neuronpedia_vector_runner import (\n",
    "    NeuronpediaVectorRunner,\n",
    "    NeuronpediaVectorRunnerConfig,\n",
    ")\n",
    "\n",
    "cfg = NeuronpediaVectorRunnerConfig(\n",
    "    outputs_dir=\"test_outputs/\",\n",
    "    huggingface_dataset_path=\"monology/pile-uncopyrighted\",\n",
    "    vector_dtype=\"float32\",\n",
    "    model_dtype=\"float32\",\n",
    "    # Small test settings\n",
    "    n_prompts_total=32,  # Small number for testing\n",
    "    n_tokens_in_prompt=64,  # Shorter sequences\n",
    "    n_prompts_in_forward_pass=16,\n",
    "    n_vectors_at_a_time=1,\n",
    "    use_wandb=False,  # Disable wandb for testing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Count: 1\n",
      "Using specified vector dtype: float32\n",
      "SAE Device: mps\n",
      "Model Device: mps\n",
      "Model Num Devices: 1\n",
      "Activation Store Device: mps\n",
      "Dataset Path: monology/pile-uncopyrighted\n",
      "Forward Pass size: 64\n",
      "Total number of tokens: 2048\n",
      "Total number of contexts (prompts): 32\n",
      "Vector DType: float32\n",
      "Model DType: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/curttigges/miniconda3/envs/sae-d/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a991bae9ea49b28a904ce6098b0cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/curttigges/Projects/SAEDashboard/sae_dashboard/neuronpedia/neuronpedia_vector_runner.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tokens = torch.load(tokens_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.\n",
      "Tokens exist, loading them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Running Batch #0 ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20ace5bd22949a794c35764cbc6988c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forward passes to cache data for vis:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6af48292604c95a3366db9220636ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting vis data from cached data:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder vectors shape: torch.Size([1, 768])\n",
      "feature_indices: [0]\n",
      "feature vectors shape: torch.Size([1, 768])\n",
      "primary acts shape: torch.Size([16, 64, 768]), feature vectors shape: torch.Size([1, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/curttigges/Projects/SAEDashboard/sae_dashboard/vector_data_generator.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary acts shape: torch.Size([16, 64, 768]), feature vectors shape: torch.Size([1, 768])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Task </span>┃<span style=\"font-weight: bold\"> Time </span>┃<span style=\"font-weight: bold\"> Pct % </span>┃\n",
       "┡━━━━━━╇━━━━━━╇━━━━━━━┩\n",
       "└──────┴──────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━┳━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTask\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPct %\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━╇━━━━━━━┩\n",
       "└──────┴──────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VectorVisData' object has no attribute 'feature_data_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m runner \u001b[38;5;241m=\u001b[39m NeuronpediaVectorRunner(vector_set, cfg)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/SAEDashboard/sae_dashboard/neuronpedia/neuronpedia_vector_runner.py:450\u001b[0m, in \u001b[0;36mNeuronpediaVectorRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\n\u001b[0;32m--> 450\u001b[0m json_object \u001b[38;5;241m=\u001b[39m \u001b[43mNeuronpediaConverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_np_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_dict\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    454\u001b[0m     output_file,\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    456\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    457\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(json_object)\n",
      "File \u001b[0;32m~/Projects/SAEDashboard/sae_dashboard/neuronpedia/neuronpedia_converter.py:92\u001b[0m, in \u001b[0;36mNeuronpediaConverter.convert_to_np_json\u001b[0;34m(model, sae_data, np_cfg, vocab_dict)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_np_json\u001b[39m(\n\u001b[1;32m     76\u001b[0m     model: HookedTransformer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     vocab_dict: Dict[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m     80\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    Convert SaeVisData to Neuronpedia JSON format.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m        str: JSON string representation of the feature data.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     features_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mNeuronpediaConverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_dict\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m NeuronpediaConverter\u001b[38;5;241m.\u001b[39m_create_batch_data(np_cfg, features_outputs)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(batch_data, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mNpEncoder)\n",
      "File \u001b[0;32m~/Projects/SAEDashboard/sae_dashboard/neuronpedia/neuronpedia_converter.py:107\u001b[0m, in \u001b[0;36mNeuronpediaConverter._process_features\u001b[0;34m(model, sae_data, np_cfg, vocab_dict)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Process all features and create NeuronpediaDashboardFeature objects.\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m features_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature_index, feature_data \u001b[38;5;129;01min\u001b[39;00m \u001b[43msae_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_data_dict\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    108\u001b[0m     feature_output \u001b[38;5;241m=\u001b[39m NeuronpediaDashboardFeature()\n\u001b[1;32m    109\u001b[0m     feature_output\u001b[38;5;241m.\u001b[39mfeature_index \u001b[38;5;241m=\u001b[39m feature_index\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorVisData' object has no attribute 'feature_data_dict'"
     ]
    }
   ],
   "source": [
    "runner = NeuronpediaVectorRunner(vector_set, cfg)\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"test_outputs/gpt2_hook_resid_pre/batch-0.json\")\n",
    "print(f\"Output file exists: {output_path.exists()}\")\n",
    "if output_path.exists():\n",
    "    with open(output_path) as f:\n",
    "        data = json.load(f)\n",
    "        print(f\"Generated data for {len(data['features'])} features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae-d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
